{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "sem3_semantics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ley7OYTNOQZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TISXB9zOVp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pycodestyle flake8 pycodestyle_magic\n",
        "!pip3 install pymorphy2[fast]\n",
        "!pip3 install keras_bert\n",
        "!pip3 install smart_open\n",
        "!pip3 install h5py\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vrAL98bLnEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%load_ext pycodestyle_magic\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from warnings import filterwarnings\n",
        "from scipy.sparse import csr_matrix\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymorphy2.tokenizers import simple_word_tokenize\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajWHE-AKGIdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kZDkVAtA6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_qiZhigOadW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caOziogKOt6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtxxoS3LnEj",
        "colab_type": "text"
      },
      "source": [
        "## word2vec + fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi1VvTCWLnEm",
        "colab_type": "text"
      },
      "source": [
        "загрузка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGYmluAgLnEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# если модель без тэгов\n",
        "model_file = \"./fasttext/model.model\"\n",
        "\n",
        "model = Word2Vec.load(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvjeMuALnEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# если модель с POS-тэггингом\n",
        "model_file = \"./fasttext/model.model\"\n",
        "\n",
        "model = KeyedVectors.load(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPywbTiLnE3",
        "colab_type": "text"
      },
      "source": [
        "проверка наличия слова в словаре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skR60EwLnE5",
        "colab_type": "code",
        "outputId": "2d361c1c-587e-47b5-de51-b3f1e65d4a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lemma = \"черепаха\"\n",
        "lemma in model.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW_A1YnfLnE-",
        "colab_type": "text"
      },
      "source": [
        "получение вектора слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T4qbTz2NLnFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.wv[lemma]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FoACjvtXLnFC",
        "colab_type": "code",
        "outputId": "59b2f26d-dca3-4dc2-bde1-da1514024039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model[lemma].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c1J3KgYLnFE",
        "colab_type": "text"
      },
      "source": [
        "получение вектора документа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpttnuU2LnFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# сделали препроцессинг, получили леммы \n",
        "lemmas = ['старинный_ADJ', 'замок_NOUN']\n",
        "\n",
        "# создаем маски для векторов \n",
        "lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
        "vec = np.zeros((model.vector_size,))\n",
        "\n",
        "# если слово есть в модели, берем его вектор\n",
        "for idx, lemma in enumerate(lemmas):\n",
        "    if lemma in model.wv:\n",
        "        lemmas_vectors[idx] = model.wv[lemma]\n",
        "        \n",
        "# проверка на случай, если на вход пришел пустой массив\n",
        "if lemmas_vectors.shape[0] is not 0:\n",
        "    vec = np.mean(lemmas_vectors, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpmuLrwKLnFJ",
        "colab_type": "text"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQ1oqk3LnFK",
        "colab_type": "text"
      },
      "source": [
        "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
        "\n",
        "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
        "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
        "    3. bert*, RuBERT - необязательно\n",
        "   \n",
        "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
        "\n",
        "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F29bbnmvO3oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/cfjv7galp6ajyr0/quora_question_pairs_rus.csv?dl=0 -O quora_question_pairs_rus.csv\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ofiTVkO-Cf",
        "colab_type": "code",
        "outputId": "a1949815-3c55-47ec-970f-6d9c23bf9f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv(\"quora_question_pairs_rus.csv\")\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
              "      <td>что произойдет, если правительство Индии украд...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
              "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
              "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
              "      <td>какая рыба выживет в соленой воде</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
              "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... is_duplicate\n",
              "0           0  ...            0\n",
              "1           1  ...            0\n",
              "2           2  ...            0\n",
              "3           3  ...            0\n",
              "4           4  ...            1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV3vosPQPpiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = list(set(df[\"question1\"]))\n",
        "query_idx = {queries[i]: i for i in range(len(queries))}\n",
        "docs = list(set(df[\"question2\"]))\n",
        "doc_idx = {docs[i]: i for i in range(len(docs))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Vm3HrJVA5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"docs.pkl\", \"wb\") as file:\n",
        "    pickle.dump(docs, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiERCtSiU_oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = drive.CreateFile({\"title\": \"docs.pkl\"})\n",
        "file.SetContentFile(\"docs.pkl\")\n",
        "file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QkpPDHPsCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dup = df[df[\"is_duplicate\"] == 1]\n",
        "row_ind = df_dup[\"question1\"].apply(lambda x: query_idx[x])\n",
        "col_ind = df_dup[\"question2\"].apply(lambda x: doc_idx[x])\n",
        "dup_matrix = csr_matrix((np.ones(df_dup.shape[0]), (row_ind, col_ind)),\n",
        "                        shape=(len(query_idx), len(doc_idx)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlP2HT6aaAVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(search_engine, queries, dup_matrix, test_size=10000):\n",
        "    true_results = 0\n",
        "    all_results = 0\n",
        "    test = np.random.choice(queries, size=test_size)\n",
        "    for query in test:\n",
        "        if dup_matrix[query_idx[query], ].sum():\n",
        "            all_results += 1\n",
        "            results = search_engine.search(query)\n",
        "            for result, score in results:\n",
        "                if dup_matrix[query_idx[query], doc_idx[result]]:\n",
        "                    true_results += 1\n",
        "                    break\n",
        "    return true_results / all_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbDPyL2gPvkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MorphAnalyzer()\n",
        "\n",
        "\n",
        "def lemmatize(text):\n",
        "    return [m.parse(word)[0].normal_form \n",
        "            for word in simple_word_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4LtlmvqLnFK",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Сравните время индексации корпуса для каждой модели "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbWiD5DZLnFL",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 2__:    \n",
        "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
        "\n",
        "Качество оцениваем так же, как в прошлом задании:\n",
        "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
        "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llVhf8CmuoiA",
        "colab_type": "text"
      },
      "source": [
        "##Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwE6Gl07QCGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir fasttext\n",
        "!wget http://vectors.nlpl.eu/repository/11/181.zip -O fasttext.zip\n",
        "!unzip fasttext.zip -d fasttext\n",
        "!rm fasttext.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih_w43IRY_D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SearchFasttext():\n",
        "    def __init__(self, data, model_file):\n",
        "        self.texts = np.array(data)\n",
        "        self.model = KeyedVectors.load(model_file)\n",
        "        self.vec = np.zeros((len(self.texts), self.model.vector_size))\n",
        "        for i in range(len(self.texts)):\n",
        "            lemmas = lemmatize(self.texts[i])\n",
        "            lemmas_vectors = np.zeros((len(lemmas), self.model.vector_size))\n",
        "            for idx, lemma in enumerate(lemmas):\n",
        "                if lemma in self.model.vocab:\n",
        "                    lemmas_vectors[idx] = self.model[lemma]\n",
        "            if lemmas_vectors.shape[0] is not 0:\n",
        "                self.vec[i] = np.mean(lemmas_vectors, axis=0)            \n",
        "\n",
        "    def search(self, query, n=5):\n",
        "        lemmas = lemmatize(query)\n",
        "        query_vec = np.zeros((self.model.vector_size, ))\n",
        "        lemmas_vectors = np.zeros((len(lemmas), self.model.vector_size))\n",
        "        for idx, lemma in enumerate(lemmas):\n",
        "            if lemma in self.model.vocab:\n",
        "                lemmas_vectors[idx] = self.model[lemma]\n",
        "        if lemmas_vectors.shape[0] is not 0:\n",
        "            query_vec = np.mean(lemmas_vectors, axis=0)\n",
        "        query_vec = np.transpose(query_vec)\n",
        "        result = np.matmul(self.vec, query_vec)\n",
        "        indices = np.argsort(result)[::-1].tolist()[:n]\n",
        "        return list(zip(self.texts[indices], result[indices]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TStU6W2joCte",
        "colab_type": "code",
        "outputId": "e515ffcc-e842-4d07-be2e-c4f6520de64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "FasttextSearchEngine = SearchFasttext(docs, \"./fasttext/model.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 52s, sys: 3.48 s, total: 1min 56s\n",
            "Wall time: 1min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG6wkqOWLnFM",
        "colab_type": "code",
        "outputId": "db943313-9850-47f4-ac1f-f470a220d4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for result in FasttextSearchEngine.search(\"рождественские каникулы\", n=10):\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('вечеринки', 7.227940226714265)\n",
            "('как празднуется Рождество', 6.348252635695177)\n",
            "('сколько учеников ежегодно посещают весенние каникулы', 6.208211912807602)\n",
            "('почему атеисты празднуют Рождество', 5.929559275163776)\n",
            "('Законопроекты', 5.816046160192412)\n",
            "('программа стипендий выпускников университетов', 5.815099947238545)\n",
            "('как мусульмане празднуют Рождество', 5.813684691519306)\n",
            "('какие праздники празднуют атеисты', 5.528922709816639)\n",
            "('каков ваш обзор каникул', 5.251107693457673)\n",
            "('почему вы празднуете рождество', 5.220994990144241)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElEoO-0zEcxq",
        "colab_type": "code",
        "outputId": "87320681-7942-42cd-b368-ced03693fa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(FasttextSearchEngine, queries, dup_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08765473402475744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eLkbuJiG6n8",
        "colab_type": "text"
      },
      "source": [
        "##ELMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTuEggjXyQ1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir elmo\n",
        "!wget http://vectors.nlpl.eu/repository/11/196.zip -O elmo.zip\n",
        "!wget https://github.com/ltgoslo/simple_elmo/archive/master.zip\n",
        "!unzip elmo.zip -d elmo\n",
        "!unzip master.zip\n",
        "!mv ./simple_elmo-master/* .\n",
        "!gzip ./elmo/vocab.txt\n",
        "!rm *.zip get_elmo_vectors.py LICENSE README.md requirements.txt test.txt vocabulary.py ./simple_elmo-master/.gitignore\n",
        "!rmdir simple_elmo-master\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ike3MvQpNS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from elmo_helpers import load_elmo_embeddings, get_elmo_vectors\n",
        "from bilm import Batcher, BidirectionalLanguageModel, weight_layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt6QfTE-Dixq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batcher, ids, elmo_input = load_elmo_embeddings(\"./elmo\")\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vONNBmxRJFF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SearchELMO():\n",
        "    def __init__(self, data):\n",
        "        self.texts = np.array(data)\n",
        "        lemm = [lemmatize(text) for text in self.texts]\n",
        "        self.vec = np.zeros((0, 1024))\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            for i in range(0, len(self.texts), 75):\n",
        "                self.vec = np.vstack((self.vec,\n",
        "                                      np.mean(get_elmo_vectors(sess,\n",
        "                                                               lemm[i:i + 75],\n",
        "                                                               batcher, ids,\n",
        "                                                               elmo_input),\n",
        "                                              axis=1)))\n",
        "\n",
        "    def search(self, query, n=5):\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            query_vec = np.transpose(np.mean(get_elmo_vectors(sess,\n",
        "                                                              [lemmatize(query)],\n",
        "                                                              batcher, ids,\n",
        "                                                              elmo_input),\n",
        "                                             axis=1)).flatten()\n",
        "            result = np.matmul(self.vec, query_vec)\n",
        "            indices = np.argsort(result)[::-1].tolist()[:n]\n",
        "        return list(zip(self.texts[indices], result[indices]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7b3mmxUTxA",
        "colab_type": "code",
        "outputId": "3f1c6fca-ba98-4082-ecb0-9fc0b8153556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "ELMOSearchEngine = SearchELMO(docs)\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 34min 19s, sys: 4min 10s, total: 38min 29s\n",
            "Wall time: 53min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF_Jf5-ZGM5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = drive.CreateFile({\"title\": \"vec.pkl\"})\n",
        "file.SetContentFile(\"vec.pkl\")\n",
        "file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anYRJPuUKYfm",
        "colab_type": "code",
        "outputId": "bd68d22e-452d-40a4-f3cd-6acb7144911f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "for result in ELMOSearchEngine.search(\"рождественские каникулы\", n=10):\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Я хочу присоединиться к некоторым хорошим курсам этического хакера в Дели для своих летних каникул, что является хорошим учебным институтом для моих праздников, поскольку я все еще новичок', 49.54284461506208)\n",
            "('что я должен делать один час в день в школе, чтобы оптимизировать свой школьный опыт, у меня есть 8-часовой школьный день, и мой единственный перерыв на обед, что я могу сделать', 48.009692874846266)\n",
            "('Таиланд медовый месяц в январе: какие лучшие скрытые драгоценные камни в бангкоке и пхукете у нас есть две недели, и мне нравится выйти из проторенного пути', 48.00078541187626)\n",
            "('я работаю по понедельникам и понедельникам, возглавляю два руководящих подразделения на танцевальных вечеринках на утреннем роликовом клинке в пятницу, делаю стрельбу из лука в субботу и делаю черлидинг в воскресенье, сколько хобби слишком много', 47.63022367818892)\n",
            "('почему мы всегда ест индейку в день благодарения, почему бы нам не съесть еще одну вкусную еду, чтобы отпраздновать благодарение', 46.101865356531604)\n",
            "('в классе учеников спрашивали об их предпочтении: яблочный банан и манго 78 из понравившихся по меньшей мере 50 из класса любили яблоки 30 любили бананы и 20 любили манго, если 6 из студентов в классе любили все три плода, какой процент студентов любил больше одного фрукта', 45.58890441770056)\n",
            "('почему у всех моих друзей есть родители, которые бросают им чрезвычайно дорогие вечеринки и отправляются в роскошные каникулы, как я могу стать менее раздраженным им?', 45.57243599501231)\n",
            "('увеличить с 5 0 до 6 5 в экзамене ielts 4 месяца в английской школе в Великобритании 22 5 часов в неделю и жить с английской семьей', 44.96689932752672)\n",
            "('между двумя работами и семейным временем у меня есть только время на 4-5 часов сна ночью, как я могу поддерживать этот темп', 44.70915047582268)\n",
            "('как время сна, а не часы сна влияют на нас, будет спать 7 часов, начиная с 2 утра или начиная с 11 вечера, делают большую разницу', 44.66167311869735)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ-IVzRE7Jvr",
        "colab_type": "code",
        "outputId": "ad3a0f13-358e-4e2c-dbcd-0bf458e7d9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "elmo_accuracy = accuracy(ELMOSearchEngine, queries, dup_matrix)\n",
        "clear_output()\n",
        "elmo_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.004369747899159664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0CCrqmR4IS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"vec.pkl\", \"wb\") as file:\n",
        "    pickle.dump(ELMOSearchEngine.vec, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcULCwkfUwxD",
        "colab_type": "text"
      },
      "source": [
        "##RuBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfAlwjZ3Ewe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras_bert.layers import MaskedGlobalMaxPool1D\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "from keras_bert import Tokenizer, load_vocabulary, get_checkpoint_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHORW2BAV0zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir rubert\n",
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v2.tar.gz -O rubert.tar\n",
        "!tar -xf rubert.tar\n",
        "!mv ./rubert_cased_L-12_H-768_A-12_v2/* rubert\n",
        "!rm rubert.tar\n",
        "!rmdir rubert_cased_L-12_H-768_A-12_v2\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joLjb1KZU01B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SearchBERT():\n",
        "    def __init__(self, data, model_path):\n",
        "        self.texts = np.array(data)\n",
        "        self.vec = np.zeros((len(self.texts), 768))\n",
        "        paths = get_checkpoint_paths(model_path)\n",
        "        inputs = load_trained_model_from_checkpoint(\n",
        "            config_file=paths.config,\n",
        "            checkpoint_file=paths.checkpoint, seq_len=50)\n",
        "        outputs = MaskedGlobalMaxPool1D(name='Pooling')(inputs.output)\n",
        "        self.model = Model(inputs=inputs.inputs, outputs=outputs)\n",
        "        self.vocab = load_vocabulary(paths.vocab)\n",
        "        self.tokenizer = Tokenizer(self.vocab)\n",
        "        for i in range(len(self.texts)):\n",
        "            tokens = self.tokenizer.tokenize(\" \".join(lemmatize(\n",
        "                self.texts[i])))[:50]\n",
        "            indices = [self.vocab[token] for token in tokens] + \\\n",
        "                [0 for j in range(50 - len(tokens))]\n",
        "            segments = [0 for j in range(50)]\n",
        "            self.vec[i] = self.model.predict([np.array([indices]),\n",
        "                                              np.array([segments])])[0]\n",
        "\n",
        "    def search(self, query, n=5):\n",
        "        tokens = self.tokenizer.tokenize(\" \".join(lemmatize(query)))[:50]\n",
        "        indices = [self.vocab[token] for token in tokens] + \\\n",
        "            [0 for i in range(50 - len(tokens))]\n",
        "        segments = [0 for i in range(50)]\n",
        "        query_vec = self.model.predict([np.array([indices]),\n",
        "                                        np.array([segments])])[0]\n",
        "        result = np.matmul(self.vec, query_vec)\n",
        "        idxs = np.argsort(result)[::-1].tolist()[:n]\n",
        "        return list(zip(self.texts[idxs], result[idxs]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE2Bd0bRnmqG",
        "colab_type": "code",
        "outputId": "c9927812-ce4c-4f70-fe30-98e95f142644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "BERTSearchEngine = SearchBERT(docs, \"./rubert\")\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 33min 8s, sys: 8min 13s, total: 1h 41min 21s\n",
            "Wall time: 1h 51min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Zu5yIO7Wqg",
        "colab_type": "code",
        "outputId": "9072d338-c401-482a-bb57-d31964979e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "for result in BERTSearchEngine.search(\"рождественские каникулы\", n=10):\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('стоит потратить деньги на то, чтобы купить что-то в Интернете в течение большого миллиарда дней, а также другие продажи, предлагаемые flipkart amazon snapdeal и т. д.', 510.45399032816727)\n",
            "('в чем разница между реальными и поддельными часами премиальных брендов, такими как omega rolex tag heuer и т. д. с точки зрения функциональности долговечности и т. д.', 507.5804296195971)\n",
            "('когда вы переписываете один сайт на другой, Google использует старый сайт seo или отбрасывает его и использует только новые метаданные seo h1 h2 на сайте и т. д.', 507.47724148129316)\n",
            "('вы подписались на приложение для веб-сайта, в котором вы получаете все свои каналы социальных сетей, например facebook twitter instagram google + quora и т. д.', 507.30373699738817)\n",
            "('где я могу найти подробное руководство по передовым практикам в качестве фрилансера, когда дело доходит до таких сайтов, как elance guru freelancer odesk и т. д.', 504.7061882486736)\n",
            "('как интернет-магазины, такие как flipkart и snapdeal, могут продавать продукты по такой низкой цене и как делают такие магазины, как продажи croma vijay и т. д.', 503.5318009161948)\n",
            "('будет ли финансовый специалист лучше, чем более качественный, чтобы получить работу в лучших консалтинговых фирмах, и т.д. bcg strategy bain и т. д.', 503.4866833057051)\n",
            "('есть ли в Интернете какое-то место, где я могу бесплатно смотреть мертвый клуб матерей, чтобы не атаковать мой компьютер, есть ли какой-либо магазин, который я могу купить в нем', 502.8273572593633)\n",
            "('каковы фильмы с наиболее интеллектуальными персонажами, вымышленными или нет, например, ozymandias dr manhattan joker heath bookger hannibal lecter и т. д.', 500.9241499661288)\n",
            "('вы могли бы стать богатыми на неопределенный срок, если нанотехнология может сделать бесконечное количество природных сокровищ, таких как ценные минералы, такие как драгоценные камни и т. д.', 499.99675177298957)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iba4PZv-JuIR",
        "colab_type": "code",
        "outputId": "66487006-8091-42ba-914d-cd52237dd973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_accuracy = accuracy(BERTSearchEngine, queries, dup_matrix)\n",
        "clear_output()\n",
        "bert_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7cgSY30Ob5e",
        "colab_type": "text"
      },
      "source": [
        "Быстрее (≈ 2 минуты) и лучше (accuracy ≈ 0.09) всего работает модель FastText. Модель ELMO обучается за ≈ 1 час и даёт accuracy ≈ 0.01, а модель RuBERT обучается за ≈ 2 часа и даёт accuracy ≈ 0.00."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9H7r5y1JkRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}