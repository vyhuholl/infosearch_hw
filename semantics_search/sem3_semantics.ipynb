{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "sem3_semantics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ley7OYTNOQZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TISXB9zOVp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pycodestyle flake8 pycodestyle_magic\n",
        "!pip3 install pymorphy2[fast]\n",
        "!pip3 install smart_open\n",
        "!pip3 install h5py\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vrAL98bLnEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%load_ext pycodestyle_magic\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from warnings import filterwarnings\n",
        "from scipy.sparse import csr_matrix\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymorphy2.tokenizers import simple_word_tokenize\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4kZDkVAtA6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtxxoS3LnEj",
        "colab_type": "text"
      },
      "source": [
        "## word2vec + fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi1VvTCWLnEm",
        "colab_type": "text"
      },
      "source": [
        "загрузка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGYmluAgLnEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# если модель без тэгов\n",
        "model_file = \"./fasttext/model.model\"\n",
        "\n",
        "model = Word2Vec.load(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VvjeMuALnEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# если модель с POS-тэггингом\n",
        "model_file = \"./fasttext/model.model\"\n",
        "\n",
        "model = KeyedVectors.load(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPywbTiLnE3",
        "colab_type": "text"
      },
      "source": [
        "проверка наличия слова в словаре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-skR60EwLnE5",
        "colab_type": "code",
        "outputId": "2d361c1c-587e-47b5-de51-b3f1e65d4a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lemma = \"черепаха\"\n",
        "lemma in model.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW_A1YnfLnE-",
        "colab_type": "text"
      },
      "source": [
        "получение вектора слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T4qbTz2NLnFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.wv[lemma]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FoACjvtXLnFC",
        "colab_type": "code",
        "outputId": "59b2f26d-dca3-4dc2-bde1-da1514024039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model[lemma].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c1J3KgYLnFE",
        "colab_type": "text"
      },
      "source": [
        "получение вектора документа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpttnuU2LnFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# сделали препроцессинг, получили леммы \n",
        "lemmas = ['старинный_ADJ', 'замок_NOUN']\n",
        "\n",
        "# создаем маски для векторов \n",
        "lemmas_vectors = np.zeros((len(lemmas), model.vector_size))\n",
        "vec = np.zeros((model.vector_size,))\n",
        "\n",
        "# если слово есть в модели, берем его вектор\n",
        "for idx, lemma in enumerate(lemmas):\n",
        "    if lemma in model.wv:\n",
        "        lemmas_vectors[idx] = model.wv[lemma]\n",
        "        \n",
        "# проверка на случай, если на вход пришел пустой массив\n",
        "if lemmas_vectors.shape[0] is not 0:\n",
        "    vec = np.mean(lemmas_vectors, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpmuLrwKLnFJ",
        "colab_type": "text"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAQ1oqk3LnFK",
        "colab_type": "text"
      },
      "source": [
        "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
        "\n",
        "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
        "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
        "    3. bert*, RuBERT - необязательно\n",
        "   \n",
        "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
        "\n",
        "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F29bbnmvO3oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/cfjv7galp6ajyr0/quora_question_pairs_rus.csv?dl=0 -O quora_question_pairs_rus.csv\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ofiTVkO-Cf",
        "colab_type": "code",
        "outputId": "d00cb261-e7fa-4e95-d372-52fb8ad0a4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv(\"quora_question_pairs_rus.csv\")\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Какова история кохинор кох-и-ноор-бриллиант</td>\n",
              "      <td>что произойдет, если правительство Индии украд...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>как я могу увеличить скорость моего интернет-с...</td>\n",
              "      <td>как повысить скорость интернета путем взлома ч...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>почему я мысленно очень одинок, как я могу это...</td>\n",
              "      <td>найти остаток, когда математика 23 ^ 24 матема...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>которые растворяют в воде быстро сахарную соль...</td>\n",
              "      <td>какая рыба выживет в соленой воде</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>астрология: я - луна-колпачок из козерога и кр...</td>\n",
              "      <td>Я тройная луна-козерог и восхождение в козерог...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... is_duplicate\n",
              "0           0  ...            0\n",
              "1           1  ...            0\n",
              "2           2  ...            0\n",
              "3           3  ...            0\n",
              "4           4  ...            1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV3vosPQPpiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = list(set(df[\"question1\"]))\n",
        "query_idx = {queries[i]: i for i in range(len(queries))}\n",
        "docs = list(set(df[\"question2\"]))\n",
        "doc_idx = {docs[i]: i for i in range(len(docs))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3QkpPDHPsCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dup = df[df[\"is_duplicate\"] == 1]\n",
        "row_ind = df_dup[\"question1\"].apply(lambda x: query_idx[x])\n",
        "col_ind = df_dup[\"question2\"].apply(lambda x: doc_idx[x])\n",
        "dup_matrix = csr_matrix((np.ones(df_dup.shape[0]), (row_ind, col_ind)),\n",
        "                        shape=(len(query_idx), len(doc_idx)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlP2HT6aaAVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(search_engine, queries, dup_matrix, test_size=10000):\n",
        "    true_results = 0\n",
        "    all_results = 0\n",
        "    test = np.random.choice(queries, size=test_size)\n",
        "    for query in test:\n",
        "        if dup_matrix[query_idx[query], ].sum():\n",
        "            all_results += 1\n",
        "            results = search_engine.search(query)\n",
        "            for result, score in results:\n",
        "                if dup_matrix[query_idx[query], doc_idx[result]]:\n",
        "                    true_results += 1\n",
        "                    break\n",
        "    return true_results / all_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbDPyL2gPvkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = MorphAnalyzer()\n",
        "\n",
        "\n",
        "def lemmatize(text):\n",
        "    return [m.parse(word)[0].normal_form \n",
        "            for word in simple_word_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4LtlmvqLnFK",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Сравните время индексации корпуса для каждой модели "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbWiD5DZLnFL",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 2__:    \n",
        "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
        "\n",
        "Качество оцениваем так же, как в прошлом задании:\n",
        "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
        "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llVhf8CmuoiA",
        "colab_type": "text"
      },
      "source": [
        "##Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwE6Gl07QCGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir fasttext\n",
        "!wget http://vectors.nlpl.eu/repository/11/181.zip -O fasttext.zip\n",
        "!unzip fasttext.zip -d fasttext\n",
        "!rm fasttext.zip\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih_w43IRY_D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SearchFasttext():\n",
        "    def __init__(self, data, model_file):\n",
        "        self.texts = np.array(data)\n",
        "        self.model = KeyedVectors.load(model_file)\n",
        "        self.vec = np.zeros((len(self.texts), self.model.vector_size))\n",
        "        for i in range(len(self.texts)):\n",
        "            lemmas = lemmatize(self.texts[i])\n",
        "            lemmas_vectors = np.zeros((len(lemmas), self.model.vector_size))\n",
        "            for idx, lemma in enumerate(lemmas):\n",
        "                if lemma in self.model.vocab:\n",
        "                    lemmas_vectors[idx] = self.model[lemma]\n",
        "            if lemmas_vectors.shape[0] is not 0:\n",
        "                self.vec[i] = np.mean(lemmas_vectors, axis=0)            \n",
        "\n",
        "    def search(self, query, n=5):\n",
        "        lemmas = lemmatize(query)\n",
        "        query_vec = np.zeros((self.model.vector_size, ))\n",
        "        lemmas_vectors = np.zeros((len(lemmas), self.model.vector_size))\n",
        "        for idx, lemma in enumerate(lemmas):\n",
        "            if lemma in self.model.vocab:\n",
        "                lemmas_vectors[idx] = self.model[lemma]\n",
        "        if lemmas_vectors.shape[0] is not 0:\n",
        "            query_vec = np.mean(lemmas_vectors, axis=0)\n",
        "        query_vec = np.transpose(query_vec)\n",
        "        result = np.matmul(self.vec, query_vec)\n",
        "        indices = np.argsort(result)[::-1].tolist()[:n]\n",
        "        return list(zip(self.texts[indices], result[indices]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TStU6W2joCte",
        "colab_type": "code",
        "outputId": "e515ffcc-e842-4d07-be2e-c4f6520de64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "FasttextSearchEngine = SearchFasttext(docs, \"./fasttext/model.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 52s, sys: 3.48 s, total: 1min 56s\n",
            "Wall time: 1min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG6wkqOWLnFM",
        "colab_type": "code",
        "outputId": "db943313-9850-47f4-ac1f-f470a220d4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for result in FasttextSearchEngine.search(\"рождественские каникулы\", n=10):\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('вечеринки', 7.227940226714265)\n",
            "('как празднуется Рождество', 6.348252635695177)\n",
            "('сколько учеников ежегодно посещают весенние каникулы', 6.208211912807602)\n",
            "('почему атеисты празднуют Рождество', 5.929559275163776)\n",
            "('Законопроекты', 5.816046160192412)\n",
            "('программа стипендий выпускников университетов', 5.815099947238545)\n",
            "('как мусульмане празднуют Рождество', 5.813684691519306)\n",
            "('какие праздники празднуют атеисты', 5.528922709816639)\n",
            "('каков ваш обзор каникул', 5.251107693457673)\n",
            "('почему вы празднуете рождество', 5.220994990144241)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElEoO-0zEcxq",
        "colab_type": "code",
        "outputId": "87320681-7942-42cd-b368-ced03693fa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(FasttextSearchEngine, queries, dup_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08765473402475744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eLkbuJiG6n8",
        "colab_type": "text"
      },
      "source": [
        "##ELMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTuEggjXyQ1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir elmo\n",
        "!wget http://vectors.nlpl.eu/repository/11/196.zip -O elmo.zip\n",
        "!wget https://github.com/ltgoslo/simple_elmo/archive/master.zip\n",
        "!unzip elmo.zip -d elmo\n",
        "!unzip master.zip\n",
        "!mv ./simple_elmo-master/* .\n",
        "!gzip ./elmo/vocab.txt\n",
        "!rm *.zip get_elmo_vectors.py LICENSE README.md requirements.txt test.txt vocabulary.py ./simple_elmo-master/.gitignore\n",
        "!rmdir simple_elmo-master\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhQ6J7zBJMd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a9e995d6-1f78-454c-99ab-20d2920548b0"
      },
      "source": [
        "!ls -R"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".:\n",
            "bilm  elmo  elmo_helpers.py  quora_question_pairs_rus.csv  sample_data\n",
            "\n",
            "./bilm:\n",
            "data.py  elmo.py  __init__.py  model.py\n",
            "\n",
            "./elmo:\n",
            "meta.json  model.hdf5  options.json  README  vocab.txt.gz\n",
            "\n",
            "./sample_data:\n",
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ike3MvQpNS3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from elmo_helpers import load_elmo_embeddings, get_elmo_vectors\n",
        "from bilm import Batcher, BidirectionalLanguageModel, weight_layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vONNBmxRJFF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SearchELMO():\n",
        "    def __init__(self, data, model_path):\n",
        "        self.texts = np.array(data)\n",
        "        lemmas = [lemmatize(text) for text in self.texts]\n",
        "        self.vec = np.zeros((0, 1024))\n",
        "        self.batcher, self.ids, self.input = load_elmo_embeddings(model_path)\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        for i in range(0, len(self.texts), 300):\n",
        "            self.vec = np.vstack((self.vec,\n",
        "                                 np.mean(get_elmo_vectors(self.sess,\n",
        "                                                          lemmas[i: i + 300],\n",
        "                                                          self.batcher,\n",
        "                                                          self.ids,\n",
        "                                                          self.input),\n",
        "                                         axis=1)))\n",
        "        self.sess.close()\n",
        "\n",
        "    def search(self, query, n=5):\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        query_vec = np.transpose(np.mean(get_elmo_vectors(self.sess,\n",
        "                                                          lemmatize(query),\n",
        "                                                          self.batcher,\n",
        "                                                          self.ids,\n",
        "                                                          self.input), axis=1))\n",
        "        self.sess.close()\n",
        "        result = np.matmul(self.vec, query_vec)\n",
        "        indices = np.argsort(result)[::-1].tolist()[:n]\n",
        "        return list(zip(self.texts[indices], result[indices]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7b3mmxUTxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fb86ea3-eda7-4777-e43f-b8a7bca3cf37"
      },
      "source": [
        "%%time\n",
        "ELMOearchEngine = SearchELMO(docs, \"./elmo\")\n",
        "clear_output()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/elmo_helpers.py:56: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:276: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:333: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:522: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/bilm/model.py:566: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:567: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123eba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123eba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123eba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123eba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/bilm/model.py:591: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bilm/model.py:536: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123ef98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123ef98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123ef98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca123ef98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca11dfa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca11dfa90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca11dfa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca11dfa90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca0d09b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca0d09b00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca0d09b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f1ca0d09b00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /content/bilm/elmo.py:92: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 300\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-64ffe97afd25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ELMOearchEngine = SearchELMO(docs, \"./elmo\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-2ce52ed5d4d0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, model_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                           self.input),\n\u001b[0;32m---> 16\u001b[0;31m                                          axis=1))\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: vstack() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaXmGNe6y_PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}